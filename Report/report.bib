@article{Mnih_2013,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
year = {2013},
month = {12},
pages = {},
title = {Playing Atari with Deep Reinforcement Learning}
}

@article{somnuk_2015,
author = {Phon-Amnuaisuk, Somnuk},
year = {2015},
month = {12},
pages = {458-467},
title = {Evolving and Discovering Tetris Gameplay Strategies},
volume = {60},
journal = {Procedia Computer Science},
doi = {10.1016/j.procs.2015.08.167}
}

@article{burgiel_1997, 
  title={How to lose at Tetris}, 
  volume={81}, 
  DOI={10.2307/3619195}, 
  number={491}, 
  journal={The Mathematical Gazette}, 
  publisher={Cambridge University Press}, 
  author={Burgiel, Heidi}, 
  year={1997}, 
  pages={194â€“200}
}

@book{Bertsekas_1996,
author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
title = {Neuro-Dynamic Programming},
year = {1996},
isbn = {1886529108},
publisher = {Athena Scientific},
edition = {1st},
abstract = {From the Publisher:This is the first textbook that fully explains the neuro-dynamic programming/reinforcement learning methodology, which is a recent breakthrough in the practical application of neural networks and dynamic programming to complex problems of planning, optimal decision making, and intelligent control.}
}

@article{TV96,
  title = {Feature-Based Methods for Large Scale Dynamic Programming},
  author = {John N. Tsitsiklis and Benjamin Van Roy},
  publisher = {Kluwer Academic Publishers},
  year = {1996}
}

@article{SO19,
  title = {The Game of Tetris in Machine Learning},
  author = {Simon Algorta and Ozgur Simsek},
  year = {2019}
}

@article{WCWT,
  title = {Tetris Artificial Intelligence},
  author = {Wei-Tze Tsai, Chi-Hsien Yen, Wei-Chiu Ma and Tian-Li Yu},
  year = {2013}
}

@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Malaysia; Pearson Education Limited,}
}

@article{gao2016incentivizing,
  title={Incentivizing evaluation via limited access to ground truth: Peer-prediction makes things worse},
  author={Gao, Alice and Wright, James R and Leyton-Brown, Kevin},
  journal={arXiv preprint arXiv:1606.07042},
  year={2016}
}

@inproceedings{gao2014trick,
  title={Trick or treat: putting peer prediction to the test},
  author={Gao, Xi Alice and Mao, Andrew and Chen, Yiling and Adams, Ryan Prescott},
  booktitle={Proceedings of the fifteenth ACM conference on Economics and computation},
  pages={507--524},
  year={2014},
  organization={ACM}
}


@article{Block62,
  title        = {The perceptron: A model for brain functioning},
  author       = {H. D. Block},  
  journal      = {Reviews of Modern Physics},  
  volume       = {34},
  number       = {1},
  pages        = {123--135},
  year         = {1962},  
}

@inproceedings{Novikoff62,
  title        = {On Convergence proofs for perceptrons},
  author       = {A. Novikoff},  
  booktitle    = {Symposium on Mathematical Theory of Automata},  
  pages        = {615--622},
  year         = {1962},  
}

@ARTICLE {s016,
    author  = "Matt Stevens, Sabeek Pradhan",
    title   = "Playing Tetris with Deep Reinforcement Learning",
    journal = "stanford.edu",
    year    = "2016"
}

@InProceedings{s017,
author="G{\"a}rtner, Thomas
and Driessens, Kurt
and Ramon, Jan",
editor="Horv{\'a}th, Tam{\'a}s
and Yamamoto, Akihiro",
title="Graph Kernels and Gaussian Processes for Relational Reinforcement Learning",
booktitle="Inductive Logic Programming",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="146--163",
abstract="Relational reinforcement learning is a Q-learning technique for relational state-action spaces. It aims to enable agents to learn how to act in an environment that has no natural representation as a tuple of constants. In this case, the learning algorithm used to approximate the mapping between state-action pairs and their so called Q(uality)-value has to be not only very reliable, but it also has to be able to handle the relational representation of state-action pairs.",
isbn="978-3-540-39917-9"
}
